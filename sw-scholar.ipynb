{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smartware Scholar (sw-scholar)\n",
    "*Author: Dino Paulo R. Gomez*\n",
    "\n",
    "Full rewrite of `TranslateAutoChecker`, a script that checks for all missing translations in the **HRSD** Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import yaml\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import lxml.etree\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# version = '2023.05.1'\n",
    "# filename = f'lib\\{module}\\{version}\\\\app.js'\n",
    "\n",
    "# Path\n",
    "module_path = r\"C:\\Infor\\ERC\\Patterns\\SW4\\UiPatterns\"\n",
    "lib_path = r\"lib\"\n",
    "\n",
    "\n",
    "\n",
    "allowed_version = \"11.1.0\"\n",
    "allowed_modules_prefix = [\"AskHR\", \"CM\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we open and parse our **CSV** file and store it to `word_list=[]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "\n",
    "\n",
    "def sanitize(input):\n",
    "    return input.replace('\"', \"\").strip()\n",
    "\n",
    "csv_filename = 'CMMain'\n",
    "csv_filepath = f'C:\\Infor\\AutomatedTranslationChecker\\csv\\{csv_filename}.csv'\n",
    "try:\n",
    "    with open(csv_filepath) as csv_file:\n",
    "        for line in csv_file:\n",
    "            if line != \"N/A\":\n",
    "                word_list.append(sanitize(line))\n",
    "    prev = len(word_list)\n",
    "    print(f\"word_list loaded with [{prev} Elements]\")\n",
    "    word_list = set(word_list)\n",
    "    print(f\"word_list removed duplicate [{prev-(len(word_list))} Elements]\")\n",
    "    print(\"word_list current length\",len(word_list), \"elements\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we loaded our **CSV** file into our list, we will check if an `resource-dictionary.json` file is existing if not then we will generate it.\n",
    "\n",
    "`build_file_tree()` is used to map out the directory tree of the **ERC** Folder to deep scan any `resources.xml`\n",
    "\n",
    "`handle_xml()` is used to parse the **XML** Files\n",
    "\n",
    "`get_resources_xml()` is used to map out the **XML TREE** inside the scanned xml files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_directories = {}\n",
    "module_files_path_list = []\n",
    "\n",
    "\n",
    "def build_file_tree(module_files_path_list):\n",
    "    check_file = 'scholar-module-list'\n",
    "    module_files_path_list = module_files_path_list\n",
    "    if os.path.isfile(check_file):\n",
    "        print('Scholar: scholar-module-list detected.')\n",
    "        with open(check_file, \"rb\") as fp:\n",
    "            module_files_path_list = pickle.load(fp)\n",
    "            print('Scholar: scholar-module-list loaded.')\n",
    "            print(f'Scholar: loaded module_files_path_list with {len(module_files_path_list)} entries')\n",
    "\n",
    "    else:\n",
    "        print('Scholar: no scholar-module-list detected, generating new list. ')\n",
    "        # Get Resource/Resources Directory from UIPatterns\n",
    "        for (dirpath, dirnames, filenames) in os.walk(module_path):\n",
    "            for dir in dirnames:\n",
    "                # Case Check due to folders being inconsistent\n",
    "                if dir.endswith(\"resource\") or dir.endswith(\"resources\"):\n",
    "                    for module in allowed_modules_prefix:\n",
    "                        if module in dirpath:\n",
    "                            resource_directories[dirpath] = os.sep.join(\n",
    "                                [dirpath, dir])\n",
    "\n",
    "        # Filter Directories to store only v11.1.0 resources\n",
    "        for key, value in list(resource_directories.items()):\n",
    "            if allowed_version not in key:\n",
    "                del resource_directories[key]\n",
    "\n",
    "        # Iterate through Resources List\n",
    "        for key, path in list(resource_directories.items()):\n",
    "            for dirpath, dirs, files in os.walk(path):\n",
    "                for filename in files:\n",
    "                    file = os.path.join(dirpath, filename)\n",
    "                    module_files_path_list.append(file)\n",
    "        with open(check_file, \"wb\") as fp:\n",
    "            pickle.dump(module_files_path_list, fp)\n",
    "            print(f'Scholar: scholar-module-list generated with {len(module_files_path_list)} entries. \\n')\n",
    "\n",
    "\n",
    "    return module_files_path_list\n",
    "\n",
    "\n",
    "module_files_path_list = build_file_tree(module_files_path_list)\n",
    "# pprint(module_files_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_generated_list = []\n",
    "resource_dictionary = {}\n",
    "\n",
    "\n",
    "def handle_xml(file):\n",
    "    temp_dict = {\n",
    "\n",
    "    }\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "    root_code = str(root.attrib[\"code\"])\n",
    "    root_ref = \"\"\n",
    "    for map_tag in root.iter(\"mapping\"):\n",
    "        mapping_dict = {\n",
    "            'value': '',\n",
    "            'ref': ''\n",
    "        }\n",
    "        for map_item in map_tag:\n",
    "            mapping_dict['value'] = str(map_item.text)\n",
    "            root_ref = \"\"\n",
    "            key_value = f'\"{root_code}.{str(map_tag.attrib[\"name\"])}\" : \"{str(map_item.text)}\"'\n",
    "            try:\n",
    "                root_ref = str(map_tag.attrib[\"ref\"])\n",
    "\n",
    "                if root_ref:\n",
    "                    mapping_dict['ref'] = str(root_ref)\n",
    "                else:\n",
    "                    mapping_dict['ref'] = ''\n",
    "            except:\n",
    "                mapping_dict['ref'] = ''\n",
    "                xml_generated_list.append(key_value)\n",
    "\n",
    "            temp_dict[str(map_tag.attrib[\"name\"])] = mapping_dict\n",
    "    if (temp_dict):\n",
    "        resource_dictionary[root_code] = temp_dict\n",
    "\n",
    "\n",
    "def get_resources_xml(resource_dictionary):\n",
    "    global xml_generated_list\n",
    "    resource_dictionary = resource_dictionary\n",
    "    check_file = 'scholar-resource-dictionary'\n",
    "    check_xml_file = 'scholar-xml-generated-list'\n",
    "    if os.path.isfile(check_file):\n",
    "\n",
    "        with open(check_file, \"rb\") as fp:\n",
    "            resource_dictionary = pickle.load(fp)\n",
    "            print(f'Scholar: {check_file} detected.')\n",
    "            print(\n",
    "                f'Scholar: resource_dictionary loaded with {len(resource_dictionary)} entries.')\n",
    "        with open(check_xml_file, \"rb\") as fp:\n",
    "            xml_generated_list = pickle.load(fp)\n",
    "            print(f'\\nScholar: {check_xml_file} detected.')\n",
    "            print(\n",
    "                f'Scholar: xml_generated_list loaded with {len(xml_generated_list)} entries.')\n",
    "\n",
    "    else:\n",
    "        for file_path in module_files_path_list:\n",
    "            handle_xml(file_path)\n",
    "        with open(check_xml_file, \"wb\") as fp:\n",
    "            pickle.dump(xml_generated_list, fp)\n",
    "            print(f'Scholar: {check_xml_file} generated.')\n",
    "        with open(check_file, \"wb\") as fp:\n",
    "            pickle.dump(resource_dictionary, fp)\n",
    "            print(f'Scholar: {check_file} generated.')\n",
    "\n",
    "    return resource_dictionary\n",
    "\n",
    "\n",
    "resource_dictionary = get_resources_xml(resource_dictionary)\n",
    "with open('scholar-resource_dictionary.json', 'w') as file:\n",
    "    file.write(json.dumps(resource_dictionary, indent=4))\n",
    "    print(\n",
    "        f'\\nScholar: scholar-resource-dictionary.json generated with {len(xml_generated_list)} elements for reference.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_tree = []\n",
    "def build_lib_tree(lib_path):\n",
    "    global lib_tree\n",
    "    for subdir, dirs, files in os.walk(lib_path):\n",
    "        for dir in dirs:\n",
    "            parent_path = os.path.join(lib_path,dir)\n",
    "            for subdir, dirs, files in os.walk(parent_path):\n",
    "                if(len(dirs)>0):\n",
    "                    lib_tree.append(os.path.join(parent_path,dirs[-1],'app.js'))\n",
    "build_lib_tree('lib')\n",
    "print(f\"lib_tree[] - {len(lib_tree)} app.js detected.\\n\")\n",
    "# pprint(lib_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_translation_dict = {}\n",
    "\n",
    "\n",
    "def parse_app_js():\n",
    "\n",
    "    global app_translation_dict\n",
    "    check_file = 'scholar-app-translation-dict'\n",
    "    # Regex Pattern\n",
    "    ext_regex_pattern = r'Ext\\.define\\(\".*?\",\\s*{\\s*extend:\\s*\".*?\",\\s*raw:\\s*\\{[\\s\\S]*?\\}\\);'\n",
    "    namespace_regex_pattern = r'^Ext\\.define\\(\"(.+?)\"'\n",
    "    raw_regex_pattern = r'raw\\s*:\\s*\\{(?:[^{}]+|\\{(?:[^{}]+|\\{(?:[^{}]+|\\{(?:[^{}]+|\\{(?:[^{}]+|\\{[^{}]*\\})*\\})*\\})*\\})*\\})*},'\n",
    "    raw_match_regex_pattern = r'{(?:[^{}]*\\{[^{}]*\\}[^{}]*)*}'\n",
    "    if os.path.isfile(check_file):\n",
    "        with open(check_file, \"rb\") as fp:\n",
    "            app_translation_dict = pickle.load(fp)\n",
    "            print(f'Scholar: {check_file} detected.')\n",
    "            print(f'Scholar: app_translation_dict loaded with {len(app_translation_dict)} entries.')\n",
    "    else:\n",
    "        for count, item in enumerate(lib_tree):\n",
    "            # # Open the file for reading\n",
    "            try:\n",
    "                with open(item, 'r', encoding='utf-8') as f:\n",
    "                    print(f'Scholar: Opening {item}')\n",
    "                    # Read the file contents\n",
    "                    contents = f.read()\n",
    "                    # Search for matches of the pattern in the file contents\n",
    "                    matches = re.findall(ext_regex_pattern, contents)\n",
    "                    namespace_code = ''\n",
    "                    if matches:\n",
    "                        for match in matches:\n",
    "                            # Get the namespace from the Ext.Define Syntax\n",
    "                            namespace_match = re.search(\n",
    "                                namespace_regex_pattern, match)\n",
    "                            namespace_code = namespace_match.group(1)\n",
    "\n",
    "                            raw_obj_match = re.findall(\n",
    "                                raw_match_regex_pattern, match)\n",
    "                            if raw_obj_match:\n",
    "                                raw_data = raw_obj_match[0]\n",
    "                                raw_data = raw_data.replace(\",\\n  }\", \"\\n  }\")\n",
    "                                ndata = yaml.load(raw_data, yaml.SafeLoader)\n",
    "                                app_translation_dict[namespace_code] = ndata\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        with open(check_file, \"wb\") as fp:\n",
    "            pickle.dump(app_translation_dict, fp)\n",
    "            print(f'\\nScholar: {check_file} generated with {len(app_translation_dict)} elements.')\n",
    "\n",
    "\n",
    "parse_app_js()\n",
    "with open('scholar-app_translation_obj.json', 'w') as file:\n",
    "    file.write(json.dumps(app_translation_dict, indent=4))\n",
    "    print(f'\\nScholar: scholar-app_translation_obj.json generated with {len(app_translation_dict)} elements for reference.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_xml(file,mapping,new_value):\n",
    "\n",
    "    parser = lxml.etree.XMLParser(strip_cdata=False)\n",
    "    tree = lxml.etree.parse(file, parser)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Find the mapping element with a name attribute of \"emptytextagent\"\n",
    "    mapping_element = root.find(f\".//mapping[@name='{mapping}']\")\n",
    "\n",
    "    # Add a new attribute to the mapping element\n",
    "    if mapping_element is not None:\n",
    "        mapping_element.set('ref', new_value)\n",
    "        tree.write(file, pretty_print=True,encoding=\"UTF-8\")\n",
    "\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_empty_locale(obj):\n",
    "    has_empty = False\n",
    "    for key in obj:\n",
    "        if not obj[key]:\n",
    "            has_empty = True\n",
    "    return has_empty\n",
    "\n",
    "def most_frequent(List):\n",
    "    return max(set(List), key = List.count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searchStr = 'Successfully Added!' #TEST CASE\n",
    "final_no_translations = []\n",
    "no_matches_in_algo = []\n",
    "# word_list = ['Consent Agreement']\n",
    "for searchStr in word_list:\n",
    "    matched_elements = []\n",
    "    matched_elements_ref = []\n",
    "    ref_occurence = []\n",
    "    for element in resource_dictionary:\n",
    "        for mapping in resource_dictionary[element]:\n",
    "            if searchStr == resource_dictionary[element][mapping]['value']:\n",
    "                resElement = f\"{element}.{mapping}\"\n",
    "                element_disc = {}\n",
    "                element_disc[element] = mapping\n",
    "                if resource_dictionary[element][mapping]['ref']:\n",
    "                    matched_elements_ref.append(element_disc)\n",
    "                else:\n",
    "                    matched_elements.append(element_disc)\n",
    "\n",
    "    for element in matched_elements_ref:\n",
    "        for key in element:\n",
    "            ref_occurence.append(resource_dictionary[key][element[key]]['ref'])\n",
    "\n",
    "    # print(\"\\nMatched_Elements\")\n",
    "    # pprint(matched_elements)\n",
    "    # print(\"\\nMatched_Elements_Ref\")\n",
    "    # pprint(matched_elements_ref)\n",
    "    for top_element in matched_elements:\n",
    "        matched_wref = []\n",
    "        no_match = []\n",
    "        for top_key in top_element:\n",
    "            # print(\"\\nEK:\", top_element, top_key, top_element[top_key])\n",
    "            if matched_elements_ref:\n",
    "                for ref_element in matched_elements_ref:\n",
    "                    for ref_key in ref_element:\n",
    "                        if top_element[top_key] == ref_element[ref_key]:\n",
    "                            matched_wref.append(ref_element)\n",
    "                        else:\n",
    "                            no_match.append(ref_element)\n",
    "\n",
    "        occurence_list = []\n",
    "        # print(\"\\nmatchedwref:\")\n",
    "        # pprint(matched_wref)\n",
    "        # print(\"\\nnomatch:\")\n",
    "        # pprint(no_match)\n",
    "\n",
    "        if matched_wref:\n",
    "            for element in matched_wref:\n",
    "                for key in element:\n",
    "                    occurence_list.append(\n",
    "                        resource_dictionary[key][element[key]]['ref'])\n",
    "            if occurence_list:\n",
    "                # print(\"\\nOccurences\")\n",
    "                # pprint(occurence_list)\n",
    "                new_reference = most_frequent(occurence_list)\n",
    "                for key in top_element:\n",
    "                    for path in module_files_path_list:\n",
    "                        if key.split('.')[-1] in path:\n",
    "                            modify_xml(path, top_element[key], new_reference)\n",
    "                            # print('\\nnew reference:', new_reference,\n",
    "                            #       'for in', top_element[key], 'in', path)\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                if has_empty_locale(app_translation_dict[top_key][top_element[top_key]]):\n",
    "                    # print(\"EMPTY LOCALE\", top_element, top_element[top_key])\n",
    "                    find = False\n",
    "                    for a_element in app_translation_dict:\n",
    "                        for a_key in app_translation_dict[a_element]:\n",
    "                            if not find:\n",
    "                                if top_element[top_key] == a_key and not has_empty_locale(app_translation_dict[a_element][a_key]):\n",
    "                                    # print(\"FOUND MATCH WITH TRANSLATION\", a_element, \"=\",\n",
    "                                    #       app_translation_dict[a_element][a_key])\n",
    "                                    find = True\n",
    "                                    for key in top_element:\n",
    "                                        for path in module_files_path_list:\n",
    "                                            if key.split('.')[-1] in path:\n",
    "                                                modify_xml(path, top_element[key], \".\".join(\n",
    "                                                    [a_element, a_key]))\n",
    "                                                # print('modified', path)\n",
    "                                        # print('FOUND',a_element,a_key)\n",
    "\n",
    "                    if not find:\n",
    "                        # print(\"Found No Reference Anywhere\")\n",
    "                        no_matches_in_algo.append(top_element)                    # print(f\"No Matches for [{a_element},{a_key}]\")\n",
    "                    \n",
    "\n",
    "                \n",
    "                    # print(\"HAS TRANSLATION\")\n",
    "            except Exception as e:\n",
    "                # print(\"NOT EXIST IN app_translation_dict\")\n",
    "                find = False\n",
    "                for a_element in app_translation_dict:\n",
    "                    for a_key in app_translation_dict[a_element]:\n",
    "                        if not find:\n",
    "                            if top_element[top_key] == a_key and not has_empty_locale(app_translation_dict[a_element][a_key]):\n",
    "                                # print(\"FOUND MATCH WITH TRANSLATION\", a_element, \"=\",\n",
    "                                #       app_translation_dict[a_element][a_key])\n",
    "                                find = True\n",
    "                                for key in top_element:\n",
    "                                    for path in module_files_path_list:\n",
    "                                        if key.split('.')[-1] in path:\n",
    "                                            modify_xml(path, top_element[key], \".\".join(\n",
    "                                                [a_element, a_key]))\n",
    "                                            # print('modified', path)\n",
    "                if not find:\n",
    "                    # print(\"Found No Reference Anywhere\")\n",
    "                    no_matches_in_algo.append(top_element)\n",
    "\n",
    "\n",
    "# print(\"\\nMatched_Elements\")\n",
    "# pprint(matched_elements)\n",
    "# print(\"\\nMatched_Elements_Ref\")\n",
    "# pprint(matched_elements_ref)\n",
    "# checkLocale(app_translation_dict['CMAdmin.resource.application.ApplicationFormDetailsResource']['configSuccessMsg'])\n",
    "# print(app_translation_dict['CMAdmin.resource.application.ApplicationFormDetailsResource']['configSuccessMsg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(no_matches_in_algo), 'length')\n",
    "json_dict = {}\n",
    "for element in no_matches_in_algo:\n",
    "    for key in element:\n",
    "        json_dict[\".\".join([key,element[key]])] = resource_dictionary[key][element[key]]['value']\n",
    "\n",
    "with open(\"final_output.json\", 'w') as file:\n",
    "    file.write(json.dumps(json_dict, indent=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
